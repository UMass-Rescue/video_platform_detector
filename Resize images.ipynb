{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T01:06:26.767934Z",
     "start_time": "2020-03-30T01:06:26.688173Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T01:10:24.952946Z",
     "start_time": "2020-03-30T01:10:24.949459Z"
    }
   },
   "outputs": [],
   "source": [
    "images_dir = Path('data/tik_tok/images/new_expanded_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T01:06:34.253979Z",
     "start_time": "2020-03-30T01:06:34.247156Z"
    }
   },
   "outputs": [],
   "source": [
    "images = [f for f in images_dir.glob('*/*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T01:06:47.291994Z",
     "start_time": "2020-03-30T01:06:36.752243Z"
    }
   },
   "outputs": [],
   "source": [
    "sizes = [cv2.imread(str(im)).shape for im in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T01:06:47.306720Z",
     "start_time": "2020-03-30T01:06:47.293394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(640, 360, 3),\n",
       " (720, 406, 3),\n",
       " (780, 540, 3),\n",
       " (960, 540, 3),\n",
       " (1024, 576, 3),\n",
       " (1080, 608, 3),\n",
       " (1280, 720, 3)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sizes = set(sizes)\n",
    "unique_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T01:08:40.185747Z",
     "start_time": "2020-03-30T01:08:40.176633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1.77', (720, 406, 3)),\n",
       " ('1.78', (1080, 608, 3)),\n",
       " ('1.44', (780, 540, 3)),\n",
       " ('1.78', (640, 360, 3)),\n",
       " ('1.78', (1280, 720, 3)),\n",
       " ('1.78', (960, 540, 3)),\n",
       " ('1.78', (1024, 576, 3))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[('{0:.2f}'.format(round(u[0]/u[1], 2)), u) for u in unique_sizes ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T01:08:40.603954Z",
     "start_time": "2020-03-30T01:08:40.598845Z"
    }
   },
   "outputs": [],
   "source": [
    "def aspect_ratio(shape):\n",
    "    return round(shape[0]/shape[1], 2)\n",
    "\n",
    "def two_decimal_format(f):\n",
    "    return '{0:.2f}'.format(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T01:08:52.016055Z",
     "start_time": "2020-03-30T01:08:41.984614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing file - data/tik_tok/images/new_expanded_dataset/centre/26267084475ef55c4eef24132995e292_20.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/centre/26267084475ef55c4eef24132995e292_21.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/centre/26267084475ef55c4eef24132995e292_18.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/centre/26267084475ef55c4eef24132995e292_19.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/centre/26267084475ef55c4eef24132995e292_22.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/top_left/26267084475ef55c4eef24132995e292_8.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/top_left/26267084475ef55c4eef24132995e292_6.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/top_left/26267084475ef55c4eef24132995e292_4.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/top_left/26267084475ef55c4eef24132995e292_3.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/top_left/26267084475ef55c4eef24132995e292_9.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/top_left/26267084475ef55c4eef24132995e292_10.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/top_left/26267084475ef55c4eef24132995e292_0.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/top_left/26267084475ef55c4eef24132995e292_2.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/top_left/26267084475ef55c4eef24132995e292_5.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/top_left/26267084475ef55c4eef24132995e292_7.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/top_left/26267084475ef55c4eef24132995e292_1.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/bottom_right/26267084475ef55c4eef24132995e292_14.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/bottom_right/26267084475ef55c4eef24132995e292_15.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/bottom_right/26267084475ef55c4eef24132995e292_12.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/bottom_right/26267084475ef55c4eef24132995e292_16.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/bottom_right/26267084475ef55c4eef24132995e292_17.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/bottom_right/26267084475ef55c4eef24132995e292_11.jpg whose shape is (780, 540, 3)\n",
      "Removing file - data/tik_tok/images/new_expanded_dataset/bottom_right/26267084475ef55c4eef24132995e292_13.jpg whose shape is (780, 540, 3)\n"
     ]
    }
   ],
   "source": [
    "for im in images:\n",
    "    img = cv2.imread(str(im))\n",
    "    if not (two_decimal_format(aspect_ratio(img.shape)) in ['1.78', '1.77']):\n",
    "        print(f'Removing file - {im} whose shape is {img.shape}')\n",
    "        os.remove(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T01:09:21.154110Z",
     "start_time": "2020-03-30T01:09:21.142051Z"
    }
   },
   "outputs": [],
   "source": [
    "images = [f for f in images_dir.glob('*/*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T01:09:38.556403Z",
     "start_time": "2020-03-30T01:09:21.668703Z"
    }
   },
   "outputs": [],
   "source": [
    "for im_path in images:\n",
    "    im = cv2.imread(str(im_path))\n",
    "    im = cv2.resize(im, (360, 640))\n",
    "    cv2.imwrite(str(im_path), im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T01:10:36.675737Z",
     "start_time": "2020-03-30T01:10:33.520229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(640, 360, 3)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [f for f in images_dir.glob('*/*')]\n",
    "sizes = [cv2.imread(str(im)).shape for im in images]\n",
    "unique_sizes = set(sizes)\n",
    "unique_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
